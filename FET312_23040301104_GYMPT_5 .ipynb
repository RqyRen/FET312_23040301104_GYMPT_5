{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9965ff73-16d4-4a53-bbac-cf7b7e65da97",
   "metadata": {
    "id": "9965ff73-16d4-4a53-bbac-cf7b7e65da97"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor,BitsAndBytesConfig\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b0dc63-e178-40c0-87b2-5bac1757019b",
   "metadata": {
    "id": "19b0dc63-e178-40c0-87b2-5bac1757019b"
   },
   "outputs": [],
   "source": [
    "!pip install torch -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ad499a-f613-4618-b302-0daed9b62d93",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "15ad499a-f613-4618-b302-0daed9b62d93",
    "outputId": "cbade138-4b1a-4fea-bad5-79c46c6a10c0"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install transformers pillow requests bitsandbytes accelerate -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a512cc8-8043-4579-b652-a57fab7f04ba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 540,
     "referenced_widgets": [
      "b81fd229c94a422ca8ebd47f920ff77a",
      "944e42ac85964bda993548636f6ac994",
      "90384c910e0c4c399e1238d1088be4ab",
      "4e03d4e5bd6a4927a75005af04bf7eca",
      "fc7d9156399b494c8429be5e8641dd0c",
      "2bb1da245065453fb33987be2f0df3af",
      "687cdf8f888e4b0a8fcaee1c152812f5",
      "c77b3599e30a465daa79507eaf05d1a8",
      "88710e3b7d254f909f153197d9acd444",
      "0dd8e7fd67b94b3abdc6f0295d201fe1",
      "82a5691b658b4d7e9d85e11f86c0b8f1",
      "ab504b0cd8bf47a795ee492245318960",
      "025d0e286c964c4ea9060d8cabbe6e4c",
      "5c4dcfe88f4d41bd9ae195a0727d9a85",
      "c6d975fa696048ef9ab09422bb3be07b",
      "54116a4558404e8a9cb7b13e4861dd22",
      "050ad36a7ffa4093b0d83948b9763415",
      "e0a48fc944f0469bae81ff14c832baed",
      "59c6d665139445c4a38ed43b0e4668d4",
      "eadfebcb98f54039a5a88abd60ac46b3",
      "066f6b425d384ffc8935ad32959613a6",
      "6aeff6a4dd7c40b488a4079a9daa3ad1",
      "d6faca42d6d845638c881f6287490ad3",
      "74e8741347cc48d0bd85f60b732fb9d6",
      "670e5d81176649719fbe1b964fe7ac99",
      "0a311ecb5e9b4fc597e4f390dc2c0f22",
      "dc0389d9a85a4510810bd106bad2225f",
      "c0b8c2efb247475d8f4ee9ee1ddbda96",
      "f2ac70d97a8b4975b64f484973fb5d07",
      "a2ce52cc609541ad84a09815d1d48f7e",
      "cbaa9ff5de8749918ba3c98d7f945857",
      "be2156b080ad4c0986cc8c250ec90dce",
      "f4cd034ed5554b8b859c0653b9ada131",
      "45e0a7cd976c456781d203caaed8129c",
      "9815c4b1debc442cb3013bf9c63abc26",
      "cf3445a785e24306a63473ebaafe5840",
      "a84852338c64498c9ba2da1c6f217441",
      "5505de7592454feda065ea0814269a65",
      "40458221b4624d3a86bf6f423be56326",
      "93a516ab49e64b67a2da8e8a76a1ebe5",
      "4c8d7aa261964b2f947ca55ffec7d556",
      "916c31e9680f4d38b0821e5c15d66a52",
      "2e82b1f6de104ca7b968f3d27da20944",
      "c06d56f499674f7abd10d6954b08b012",
      "f89a60b42e2c4bf0991a45029079589a",
      "740df750772f4821acab02219d0e4bef",
      "c5fccb18808d408f94e8a43768ce2da3",
      "9c71cfea02b64c8dbefad15d7df31454",
      "b859652b0ef24f1dba80b28e40e3210f",
      "92be4bf886354752982a281c2d9dd20e",
      "84635d2454214ae2aa3fdcd3279a1090",
      "ac25d9ab4bc44ac998fecb1d343c6615",
      "17639f7c4fab48909b3e5403c0b195fb",
      "f46be97de3394683a5349c7074a527e5",
      "11dac1b741c04e6eb45eeaa5fbd7f8dc",
      "3f81cd9ceb624474b94621ccc0015c20",
      "ff022ab9928b47f49a38fdd39f458c1b",
      "63f6843dbd7a4d0da811e713f2f9d82c",
      "244c812747fd4bce8b436dc962f16a42",
      "3e778d2e0e0c4ea7b19d1b8e7a7e2603",
      "e0259c29092a42c99accfacecc7b7dc5",
      "596d6c9c1bac4460be04ef31b4a7bf41",
      "23a9424f0cae471a9c64393ed52d7ccf",
      "34055a6972b544e195bf3f7dfb968be7",
      "dc2385dd3ead41d4bd7285381369942b",
      "6970ec6746064720bd76c249a562207a",
      "b817a228021249729bb2a855fd058739",
      "e077f64f22004cb4874395580cb56207",
      "85ea8956b7b84b239abc4a4fcafa21c9",
      "479015feda054c6c99e8751f696a3c6c",
      "8ac40768c55f47c4a15646770cdfd7b9",
      "d323c6181644448eb12506356966ec37",
      "61749402a73842feae17609fb600cf09",
      "4736ccbc30c042b69a94c305290e8f09",
      "3432423cf622426cb10eb16dce332045",
      "057d11d214f9464482b10ecb4f36b61d",
      "ac42ea5231d34e8d8216dfc78ee4b9cc",
      "62382c06e7ff476abde405612181503b",
      "5e225b84fbc6497db93f6574d2781f1d",
      "02bf223bcc3d49989e9832a19f84b2db",
      "6d7ac9b5429a495ba0fd768bb67e0484",
      "ad3c9c3c3c684f6087cb8a4c03310a6e",
      "e17947d0e719426b9cad2c03b38ff0ef",
      "4d4687cbbe4e4a3fb6b0454dd8822c87",
      "ac393bdb91224ba9ab09b4c7f590d95a",
      "5529e15f2aac4cdc97309713f1015fe3",
      "60564c50a2f644aab68f862b3eb0d3b1",
      "f26162ac9d3544edada11239d3fddf8f",
      "c8869974e2c843de99e04b7e839ae06b",
      "f77d08cc5c454bc39313b61368a18c99",
      "c98d88323a0145a6bd3ffa5a046fa582",
      "79544803d5304850a2130fa64fbec834",
      "ca3fb3ccdd064d4a8a566fbfd58631c8",
      "83380bd7662340f89159d233bb0f495f",
      "10bf8535f7744930aa1283ac8c54c24d",
      "f784b19860294991bdb591445411e67f",
      "69feae5ab495480590981f9a53dcb60a",
      "e867f82056d24ef686fe19569c50e4c3",
      "e1b9170ff7c8494e89f3b67f52138126",
      "202fd5462c52449a9c35a37b3ce61bd9",
      "1c580ea1a15343feb83a7870394874ac",
      "16e315d9204948a397fb6aa5702a1f14",
      "a718309a83c9477db81df764f35c4eae",
      "a91f4bc9d3d5470f99ee137c920505d6",
      "0eda9133416d4cb39309c821d8d5de4d",
      "0a7bdf6080e840c9bfafba50fb853c3f",
      "b300e70641544f559959b509c440b15c",
      "cdad377d3ee348a58c6804398963de27",
      "fd6ee0dd7fe94340b4ae6d68408101f9",
      "498945bf27c94beba66501da9c007114",
      "41fbe4d0259c4be1826b1168ddd19b0f",
      "375f4f1b7bd6425aa7a1e9cbf81b3416",
      "1b28a8bd58914d8981b60ccaa341ecd6",
      "91923803502247f99f12eec94c0638c2",
      "3d99365aaa2d431787929471d32fbfbf",
      "8b43c85015664a6380792084395c617a",
      "a2d45ec7c2c0483c8f00e43235fa251c",
      "1f84ab0a2857445fa48caf1aca3c8fbb",
      "e45af602149f453ca787717cde343bba",
      "c93f41353bc747a180754acc0ded7c3b",
      "bad402dca79d4d6f852fea25c70683e3",
      "2cb5b9fc20894c5184abcab8a1f62446",
      "feda5a2cc7724972bfd6038b2a6e7f96",
      "f8454a738f5e42a3b592648b3d3bb808",
      "bff5566986a4455ea3e10744e4a998ee",
      "d11e9c6c01f84b0794a19138b41d5394",
      "d8a55b3331ca48e08b9b714bc468fadc",
      "b48e82ed453147a1bff8f1cd64575ba9",
      "42cb4c2266734938b5076bbbfdef9c24",
      "b5a484e8db334e2dad094dcfe4bc1387",
      "f4fa8b5f3f3149e582f39749c1e30572",
      "de463e82f5a24d5fbb3372c7339b1ddb",
      "15f5959a72c343a8b8b9a44c270aeec8",
      "174b9560315a4834a827390342a0f1b4",
      "a04dc65e1c454cd4a16105d351114ab0",
      "a252f108e81a42e4afe4145b83131a55",
      "2a70a4bd0946407796f7ff426ee59da2",
      "de25e1aea01f4166b8d8c7bf30653c01",
      "0c0989857ee846de9c66bec6311f8c8b",
      "418639af2fea4e3283d624d887e3016f",
      "8ac5232799994abe85bfccc62261b5ed",
      "b30795f22dda4735a5156fcd3ab44b1c",
      "862b54bb87fe47229b3f3adbaedfc0bf"
     ]
    },
    "id": "6a512cc8-8043-4579-b652-a57fab7f04ba",
    "outputId": "a2d143fb-0e3d-4e97-f6d6-3bdd5df15ec9"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b81fd229c94a422ca8ebd47f920ff77a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 772fb556-cf34-4ece-affb-60e98accddd0)')' thrown while requesting HEAD https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct/resolve/main/model.safetensors\n",
      "WARNING:huggingface_hub.utils._http:'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 772fb556-cf34-4ece-affb-60e98accddd0)')' thrown while requesting HEAD https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct/resolve/main/model.safetensors\n",
      "Retrying in 1s [Retry 1/5].\n",
      "WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ab504b0cd8bf47a795ee492245318960"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d6faca42d6d845638c881f6287490ad3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/429M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "45e0a7cd976c456781d203caaed8129c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/3.99G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f89a60b42e2c4bf0991a45029079589a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3f81cd9ceb624474b94621ccc0015c20"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/272 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b817a228021249729bb2a855fd058739"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/347 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "62382c06e7ff476abde405612181503b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c8869974e2c843de99e04b7e839ae06b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "202fd5462c52449a9c35a37b3ce61bd9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "41fbe4d0259c4be1826b1168ddd19b0f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2cb5b9fc20894c5184abcab8a1f62446"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "chat_template.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "15f5959a72c343a8b8b9a44c270aeec8"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "model_name = \"Qwen/Qwen2-VL-2B-Instruct\"\n",
    "\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    model_name,\n",
    "    dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"sdpa\"\n",
    ")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e9a9ae-65e0-4efe-9d45-3dfcdc6164db",
   "metadata": {
    "id": "a5e9a9ae-65e0-4efe-9d45-3dfcdc6164db"
   },
   "outputs": [],
   "source": [
    "!pip install hf_xet -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d796895-ef82-4d81-8097-931b9337cacc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9d796895-ef82-4d81-8097-931b9337cacc",
    "outputId": "672843c3-938f-4be4-9f22-c77168c68793"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tabii ki, bu men√ºdeki kalori sayƒ±sƒ± 500'dir:\n",
      "\n",
      "1. 2 adet kahve: 100 kalori\n",
      "2. 1 tane tohumlu kek: 100 kalori\n",
      "3. 1 adet s√ºt: 40 kalori\n",
      "4. 1 adet √ßay: 60 kalori\n",
      "5. 1 adet biber: 70 kalori\n",
      "6. 1 adet mƒ±sƒ±r: 80 kalori\n",
      "7. 1 adet zeytinyaƒüƒ±: 90 kalori\n",
      "8. 1 adet kuru balƒ±k: 100 kalori\n",
      "9. 1 adet kuru sebzeler: 100 kalori\n",
      "10. 1 adet kuru domates: 100 kalori\n",
      "\n",
      "Bu men√ºdeki toplam kalori sayƒ±sƒ± 500 kalori olacaktƒ±r. Bu men√ºdeki besinler arasƒ±nda √ße≈üitli besinler bulunur ve bu besinlerin kalori a√ßƒ±sƒ±ndan farklƒ±lƒ±k g√∂sterir. Bu nedenle, her ki≈üi i√ßin belirli bes\n"
     ]
    }
   ],
   "source": [
    "question = \"Bana 500 kalorilik bir men√º √∂nerirmisin?\"\n",
    "\n",
    "text_prompt = processor.apply_chat_template(\n",
    "    [{\"role\": \"user\", \"content\": question}],\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "inputs = processor(\n",
    "    text=[text_prompt],\n",
    "    images=None,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True\n",
    ").to(model.device)\n",
    "\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=250,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.1\n",
    ")\n",
    "\n",
    "answer = processor.batch_decode(output, skip_special_tokens=True)[0]\n",
    "print(answer.split(\"assistant\")[-1].strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# 1. Resmi Al\n",
    "url = \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQTqYqldSyrIb2y5m_oCLy4VYsL6meCvP2jXg&s\"\n",
    "headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "response = requests.get(url, headers=headers)\n",
    "image = Image.open(BytesIO(response.content))\n",
    "\n",
    "# 2. PROMPT'U (Modeli base model i√ßin kƒ±rmanƒ±n yolu)\n",
    "prompt = \"\"\"\n",
    "Bu bir g√∂rsel analiz ve nesne tanƒ±ma testidir.\n",
    "Fotoƒüraftaki yiyecekleri tespit et (Hamburger, patates vb.).\n",
    "Her bir yiyecek i√ßin genel besin veritabanlarƒ±nda (√∂rneƒüin USDA) kabul edilen ortalama kalori deƒüerlerini yaz.\n",
    "Ki≈üisel tavsiye verme, sadece nesneleri ve standart kalori deƒüerlerini listele.\n",
    "Sonu√ßlarƒ± ≈üu formatta ver:\n",
    "- Yiyecek Adƒ±: Tahmini Kalori\n",
    "- Toplam: Tahmini Toplam\n",
    "\"\"\"\n",
    "\n",
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\", \"image\": image},\n",
    "            {\"type\": \"text\", \"text\": prompt},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "# 3. ƒ∞≈üleme\n",
    "text_prompt = processor.apply_chat_template(conversation, tokenize=False, add_generation_prompt=True)\n",
    "inputs = processor(text=[text_prompt], images=[image], return_tensors=\"pt\", padding=True).to(\"cuda\")\n",
    "\n",
    "# 4. Cevabƒ± Al\n",
    "output = model.generate(**inputs, max_new_tokens=256)\n",
    "print(processor.batch_decode(output, skip_special_tokens=True)[0].split(\"assistant\")[-1])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LEIoajrP_pQe",
    "outputId": "c0aa759f-e31c-481f-e9ca-fe572a1c8b61"
   },
   "id": "LEIoajrP_pQe",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Bu fotoƒüraf, McDonald's'ƒ±n \"McGriddle\" nesnesini g√∂steriyor. Bu yiyecek, 100 gram (3.5 un) bir kahvaltƒ± i√ßin 300 kalori i√ßerir. Bu, genel besin veritabanlarƒ±nda kabul edilen ortalamalƒ± kalori deƒüerlerinin 100 gram (3.5 un) bir kahvaltƒ± i√ßin 300 kalori olduƒüunu g√∂sterir.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install torch transformers peft datasets bitsandbytes accelerate qwen-vl-utils -q"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q2aeJScE0klA",
    "outputId": "4c4e8a5e-429f-4b26-c154-37b7a2636488"
   },
   "id": "q2aeJScE0klA",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m40.5/40.5 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install torch transformers peft datasets bitsandbytes accelerate qwen-vl-utils -q"
   ],
   "metadata": {
    "id": "YpuFemZ1J2Xt"
   },
   "id": "YpuFemZ1J2Xt",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "import shutil\n",
    "from google.colab import drive\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForVision2Seq,\n",
    "    AutoProcessor,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig,\n",
    "    default_data_collator\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "\n",
    "# --- 1. AYARLAR ---\n",
    "FILE_NAME = \"data.jsonl\"\n",
    "MODEL_ID = \"Qwen/Qwen2-VL-2B-Instruct\"\n",
    "OUTPUT_DIR = \"/content/qwen2-vl-turkish-food-v2\"\n",
    "\n",
    "# Dosya kontrol√º\n",
    "if not os.path.exists(FILE_NAME):\n",
    "    raise FileNotFoundError(f\"‚ùå HATA: '{FILE_NAME}' yok! L√ºtfen soldan s√ºr√ºkleyip y√ºkle.\")\n",
    "\n",
    "# --- 2. MODEL HAZIRLIƒûI (T4 GPU UYUMLU) ---\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16 # T4 i√ßin float16 (bf16 deƒüil!)\n",
    ")\n",
    "\n",
    "print(\"üöÄ Model Y√ºkleniyor...\")\n",
    "model = AutoModelForVision2Seq.from_pretrained(\n",
    "    MODEL_ID, quantization_config=bnb_config, device_map=\"auto\", torch_dtype=torch.float16, trust_remote_code=True\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "\n",
    "# LoRA Ayarlarƒ±\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "peft_config = LoraConfig(\n",
    "    r=64, lora_alpha=128,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_dropout=0.05, bias=\"none\", task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "# --- 3. VERƒ∞ HAZIRLIƒûI ---\n",
    "def format_jsonl_to_chat(example):\n",
    "    prompt = example['instruction'] + (f\"\\n{example['input']}\" if example.get('input') else \"\")\n",
    "    messages = [{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": prompt}]},\n",
    "                {\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": example['output']}]}]\n",
    "    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)\n",
    "    inputs = processor(text=[text], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    inputs['labels'] = inputs['input_ids'].clone()\n",
    "    inputs['labels'][inputs['labels'] == processor.tokenizer.pad_token_id] = -100\n",
    "    return {\"input_ids\": inputs['input_ids'][0], \"attention_mask\": inputs['attention_mask'][0], \"labels\": inputs['labels'][0]}\n",
    "\n",
    "print(\"üìö Veri i≈üleniyor...\")\n",
    "dataset = load_dataset(\"json\", data_files=FILE_NAME, split=\"train\")\n",
    "formatted_dataset = dataset.map(format_jsonl_to_chat, remove_columns=dataset.column_names)\n",
    "\n",
    "# --- 4. Eƒûƒ∞Tƒ∞M ---\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=10,    # 10 Epoch\n",
    "    fp16=True,              # ‚úÖ T4 GPU i√ßin A√áIK\n",
    "    bf16=False,             # ‚ùå T4 i√ßin KAPALI\n",
    "    logging_steps=5,\n",
    "    save_strategy=\"epoch\",\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=formatted_dataset, data_collator=default_data_collator)\n",
    "\n",
    "print(\"üî• Eƒûƒ∞Tƒ∞M BA≈ûLIYOR... (Hƒ±zlƒ± bitecek)\")\n",
    "trainer.train()\n",
    "\n",
    "# Kaydet\n",
    "trainer.save_model(OUTPUT_DIR)\n",
    "processor.save_pretrained(OUTPUT_DIR)\n",
    "print(\"‚úÖ Eƒüitim Bitti!\")\n",
    "\n",
    "# --- 5. DRIVE YEDEKLEME ---\n",
    "print(\"üì¶ Google Drive'a yedekleniyor...\")\n",
    "drive.mount('/content/drive')\n",
    "drive_dest = \"/content/drive/My Drive/YapayZekaModellerim/TurkishFood-Qwen2B-Final\"\n",
    "\n",
    "if os.path.exists(drive_dest):\n",
    "    shutil.rmtree(drive_dest)\n",
    "shutil.copytree(OUTPUT_DIR, drive_dest)\n",
    "\n",
    "print(f\"üéâ TEBRƒ∞KLER! Modelin Drive'da: {drive_dest}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "259b061bda51473d9a75db3c08e2c03d",
      "61505b6733304bcf87e835eb9456b027",
      "640486dc7f784d079e89d78b5b356b25",
      "48cecce38a6140d8bba2951749cb4a6a",
      "feacc0ccedf248f1b8d849bfe0629eb9",
      "45ae7d767c9f4a069f3d4d828d1fc88c",
      "4e49f4e63fa145989647bf33afdfc332",
      "b94413cbebbc48beb4cd9759de5e40c1",
      "e457937f671a469abe93278d651fe550",
      "d92cb920d845418c9e8551034aa725fc",
      "306f5d3518b04bdd87fde40c84005085",
      "cf9edf753eaa43869007bb9608b28552",
      "dad4ae33f3ce4161bc415c9e1503a9e4",
      "be4d4f9a9fb14405b61a63695013cea0",
      "1acf2e7e18fa4e49b960618cde67f7f9",
      "6616e77d34674f6e85f24a26d9078c28",
      "a5565389b6dd4e52b68f67a9ed0caa67",
      "412bc61f552348f7829c2980702a4255",
      "11b6f81ce5074827a600a5624ab1ef80",
      "8cd6eb0076a7473e9423844da3c44385",
      "0215fc76d8fd4ca1b79da8cb8b604a9c",
      "db6ab89163634e948d656a7cc4f6b4e6",
      "889c5b89eb2140ef846a7c86e2255f37",
      "ea2ad9ff47f941d48835103a447333c3",
      "50f37dd0c56f403e800e1a9c2e738e18",
      "31190e92b89a4c98b56791d33e3906f2",
      "947a66e7ccf1451cb8e6373ab4f309fc",
      "0086bb525d09450cb675b7f8cc1ac96f",
      "4788edad515b46c3bb233c77e0bbc445",
      "73e54ba91e0b45609fc5d148e7badca7",
      "5142d9b07b2f428c8577330435bf91b0",
      "ea1324cab20d453ba55facf08fca5edb",
      "a68fa49fc6e64fd5a98ea4c4f9bfbcf1",
      "f2bd229beb674730929d0d1e22c2cbb2",
      "18c6177e64234ef69ff352cd25fba264",
      "22efc70ac9614bfb9a093887a3841980",
      "501f4aff8efa4a488b81fbde470c1cc8",
      "c62e127b9aff4a02b808745cc514bed6",
      "e875158b88584b2b8c4bf1a07afc553b",
      "306dc31f6b7a4148aa9ca14c0744edc9",
      "0f381a9000134710b488cfe38485be43",
      "017ce441bd764623a067f7e6fcfbcae3",
      "17ce99a12e724ebc9075a3bcc3eb0101",
      "2e85d726b94249bfbb744eb878fadf75",
      "16c0e4b6229c4a49bf17c3fa289ac230",
      "455f2a515f9f4dd1badb67b0b4254eaa",
      "86983aefa86f4cf190227117b9db3a05",
      "18b7bbdd03684cd4b4f0abea33a949e4",
      "f1a82d8d7bea4c8fac6ad8e8fe1e0fb3",
      "3cfe72cb8fec4a548f599771ac43e3b7",
      "222dd18c7a104924b1e3666229e8f919",
      "a30298662b8b42c7976d366fedb215e2",
      "a29dd9685e864b918b8863e2bff49825",
      "eb2c48898fc247a5a8d204a6b7c06cad",
      "06595fb9f0ed4c999ea5553d8cb31862",
      "899935fb867b4fbbb7e59f74f515a906",
      "90edab3bea1e4c6088d7f8598c1d8f18",
      "c6e4cfdafcd142b681729801aa881048",
      "57f66f6d85744230af7b00a7808ac6d1",
      "3995d77f5a4f49f29e9b0616d953941a",
      "5e7785d4ee7f4a0aaf1fb1a2be9cabe2",
      "2762752cb4094bdf9f6ed09c787024ad",
      "a336a2a10a3340f0b19a002a096b2856",
      "f577826b51454f2abe793ccb456defc5",
      "1b29f72978214aecb53b795b8c4aa281",
      "8c8aa13a060f4e91b82a8c63e0c27a04",
      "5116b40be1c94e95ab2f0081b49968ba",
      "82d1d9847da04b0c8cc474e25d44675e",
      "b8f8dd3372784c72bc391d1d1dd84425",
      "09649340a333491a916bf7ec8c3faf26",
      "da5789c8dd6548e8b3677fc2a33e5f12",
      "50f01cbf231d438abecb73606bdd310b",
      "dce8c6a3f8f4435788e110727fe22e8c",
      "64a2456eebd54fca89af265ad1f3b56a",
      "2b11d71398ed4c60a8698f6cf5d26f18",
      "b1d9085b185946eba785c80f91963ec2",
      "a2c3a4d8ac43439ea19859bf64443ce9",
      "a45a601554104950b98b95d0a0483ada",
      "fb0ff07cd8674db58d83a62d0ef8f010",
      "5d9def47eb2c46238f44eda27220d4b5",
      "aeda941744d04357b8868b36562f4278",
      "c984cc9d1c7e4036b1a7479d8576eed3",
      "9eb2f552bd5040b698ce1461e9aaa286",
      "2afac0e26ec04cec80b6355e38b9ed26",
      "a9e289b38b244348a06031c438d16c34",
      "486f0668bfcd4fa6a03276aa2d8adcda",
      "3ae528bd484442d181ba0d87b6443788",
      "cfbb4bcc1dec4138831573c10664c46b",
      "a2da040ef4864cbb9db45fc571be37a7",
      "700673f028b0434a958c8e27a5c79c5c",
      "d0128c1592db4d4b8244657a7956b180",
      "9fac1e5e9978469dbf319752c2d2377a",
      "194499482282477fb5b41d3ed6427d07",
      "94efe05e1723409ca0e1cfa83326986c",
      "1b3aa6d375604e14967d51e09bef117d",
      "72086f9e19ae417d96f816df9816d325",
      "edad18ffc2fd45c3a7ad7d1b218db328",
      "b077e33cc92f4d1d9d695d3bd028c3dc",
      "ccdc4df807e14f1f9ced6e44c3cad1a6",
      "c2dbacc1a5874c3c88a3944e299ecbd1",
      "5d8242b7932d4434ab650afb86fdb8a3",
      "5c8bb7ef56774dee9bb155dca9a78f8c",
      "282e17af087f4d16912063ad8c8d01ec",
      "ab44111d14a941dba00caa5f97b579b8",
      "dbc17b5d0a774151b255e7e12c23d57a",
      "34c94a6ed9d947a58efa44390184eab4",
      "00d4aeaad7a8401abfb1d1b8ba17583f",
      "adbd92a5c85f482b97e25f9dc94edc76",
      "b59f6aa0817e48c98ecfd6f11dc87706",
      "e1af809028594236b0810ca3cf74f507",
      "29d8d0b615e94953800b20990574fd9d",
      "bdfc2ac505a24d36b5be80ad8074d9df",
      "e68c33870ad14b5ba93babd6c23f5b1d",
      "a488a2f4414145c9b5be450c96176c9c",
      "72b941a5ab0c4ac3ae2590d832d887d2",
      "0bfa5689871c4396b0479f7abc13fe9e",
      "c651986fc9de4c2d95bb6912ee20ab4c",
      "3977094845ca48ec8d8edd81c32d0b65",
      "7be921a04ee341f896580b359af1bf70",
      "81f61e5872874980b4d325edc734ee61",
      "251821d309a5464baeb735802dcd9c95",
      "849ff3c303c846a890553273ba22be16",
      "05eecffc3056407086fa14efe8cde364",
      "80d6b72c86b1460bbf20e9a1225d4ccd",
      "7cecf62a3e7d410aa0553289b74ef8a0",
      "d0d746f3687144489da1445507d951c5",
      "a42debf504b94c879b31ab926ec8db10",
      "cc4f7559e39c4970b84a7d9d697f2a29",
      "2ae8dc607e2644259867b7cf4ed33c94",
      "ffc70ab54dc54855b6b5b3e2d73175cd",
      "e7066f89487243b4a4943a7ff5ba683d",
      "73d07fe286444c05b8a676c961f32c05",
      "c12d7e083d6a45a2b1e728f0bd3372c5",
      "fd71875c4dc34ef89013a0236939f0a3",
      "a5778b9da2104ff9980a6d44f6a7ea64",
      "43bdbff0ce5a4b7e8fd143001006754b",
      "b32001709e0f4f2ba39f25f65aff7121",
      "169655fa268f4879860bdb6c76a351e8",
      "7b5e1cb781e34522aa8d1c25d2ca823d",
      "249445e4f4d94c76b254d7013af29efa",
      "2c5b0965af68403285798ad1771b0636",
      "7a3c68ae004341009c99dc894561f20b",
      "7bf375410d1148d4bf9231f212c9d58f",
      "930ec903a3794bfead8c92b77dafa497",
      "03b72e0ac961438d9e66c66f067d25e4",
      "b6c526bfcb0b48928e9a0d35f9519338",
      "ab4927f1b71d458cb6d7ddee9a8b1bbb",
      "22f253193c8747e9b5d48847bff101f7",
      "39f89cc2212e4a949de9eaa2139fecf6",
      "4bcd6f2f8141406ab8321b11aef7b83d",
      "6033a39249d74e91ac9ed415492e8be4",
      "85ac97bbf13a49fdb690cc104d18ae5b",
      "ea5305d582844d2eb363304b19970d71",
      "3c751aa0d8f549afb43d18767cf7fe83",
      "b9341a54be234e728942230fae936d2e",
      "7465272e30c44256b9793a9c36d8593d",
      "4ed8cca187df45e4b7051be6a7ed12fc",
      "1b04154de5bb4e80a67e5ccd65ccb56b",
      "58641a8a6d774bdc9f55712423b88f1d",
      "9ce2e969fc29467c96c3a3f4c53bc215",
      "507080c298254d578dede78f306d14bf",
      "694d63c40e5746afa6cd13f621cd835b",
      "9a3e8f46053e40f7961d5628acf08ff1",
      "fccc7dbc17f44e01865220c65d6b0bc2",
      "438b9547c3be42439035c91e0fdd8807"
     ]
    },
    "id": "J1diJ7SbN67D",
    "outputId": "4ec3e0d7-cb89-47f1-cc1b-70d89969e39d"
   },
   "id": "J1diJ7SbN67D",
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "üöÄ Model Y√ºkleniyor...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/modeling_auto.py:2284: FutureWarning: The class `AutoModelForVision2Seq` is deprecated and will be removed in v5.0. Please use `AutoModelForImageTextToText` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "259b061bda51473d9a75db3c08e2c03d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cf9edf753eaa43869007bb9608b28552"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "889c5b89eb2140ef846a7c86e2255f37"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/3.99G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f2bd229beb674730929d0d1e22c2cbb2"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/429M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "16c0e4b6229c4a49bf17c3fa289ac230"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "899935fb867b4fbbb7e59f74f515a906"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/272 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5116b40be1c94e95ab2f0081b49968ba"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/347 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a45a601554104950b98b95d0a0483ada"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a2da040ef4864cbb9db45fc571be37a7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c2dbacc1a5874c3c88a3944e299ecbd1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "29d8d0b615e94953800b20990574fd9d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "849ff3c303c846a890553273ba22be16"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "chat_template.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c12d7e083d6a45a2b1e728f0bd3372c5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "üìö Veri i≈üleniyor...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "930ec903a3794bfead8c92b77dafa497"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b9341a54be234e728942230fae936d2e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "üî• Eƒûƒ∞Tƒ∞M BA≈ûLIYOR... (Hƒ±zlƒ± bitecek)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='130' max='130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [130/130 06:59, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.174500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.832600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.093300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.663100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.723700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.173700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.925400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.962400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.534100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.537100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.328900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.259700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.296700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.150400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.135400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.118600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.076700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.098600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.074300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.066800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.055900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>0.058200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.048200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.048200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.052500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "‚úÖ Eƒüitim Bitti!\n",
      "üì¶ Google Drive'a yedekleniyor...\n",
      "Mounted at /content/drive\n",
      "üéâ TEBRƒ∞KLER! Modelin Drive'da: /content/drive/My Drive/YapayZekaModellerim/TurkishFood-Qwen2B-Final\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"üßπ Eski ve bozuk s√ºr√ºmler temizleniyor...\")\n",
    "!pip uninstall -y bitsandbytes transformers peft accelerate\n",
    "\n",
    "print(\"‚ú® En g√ºncel ve uyumlu s√ºr√ºmler GitHub'dan y√ºkleniyor...\")\n",
    "!pip install -U bitsandbytes\n",
    "!pip install -U git+https://github.com/huggingface/transformers.git\n",
    "!pip install -U git+https://github.com/huggingface/peft.git\n",
    "!pip install -U git+https://github.com/huggingface/accelerate.git\n",
    "!pip install -U qwen-vl-utils\n",
    "\n",
    "print(\"‚úÖ Kurulum tamamlandƒ±! ≈ûimdi eƒüitim kodunu √ßalƒ±≈ütƒ±rabilirsin.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "82P-tcNX4Fyu",
    "outputId": "510c7e0e-3281-4594-89f9-2953fcab7f65"
   },
   "id": "82P-tcNX4Fyu",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "üßπ Eski ve bozuk s√ºr√ºmler temizleniyor...\n",
      "Found existing installation: bitsandbytes 0.48.2\n",
      "Uninstalling bitsandbytes-0.48.2:\n",
      "  Successfully uninstalled bitsandbytes-0.48.2\n",
      "Found existing installation: transformers 4.57.3\n",
      "Uninstalling transformers-4.57.3:\n",
      "  Successfully uninstalled transformers-4.57.3\n",
      "Found existing installation: peft 0.18.0\n",
      "Uninstalling peft-0.18.0:\n",
      "  Successfully uninstalled peft-0.18.0\n",
      "Found existing installation: accelerate 1.12.0\n",
      "Uninstalling accelerate-1.12.0:\n",
      "  Successfully uninstalled accelerate-1.12.0\n",
      "‚ú® En g√ºncel ve uyumlu s√ºr√ºmler GitHub'dan y√ºkleniyor...\n",
      "Collecting bitsandbytes\n",
      "  Using cached bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.9.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (25.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n",
      "Using cached bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl (59.4 MB)\n",
      "Installing collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.48.2\n",
      "Collecting git+https://github.com/huggingface/transformers.git\n",
      "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-91i5cxgn\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-91i5cxgn\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit cac0a28c83cf87b7a05495de3177099c635ba852\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (3.20.0)\n",
      "Collecting huggingface-hub<2.0,>=1.0.0 (from transformers==5.0.0.dev0)\n",
      "  Downloading huggingface_hub-1.1.6-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (0.22.1)\n",
      "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (0.20.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.0.0->transformers==5.0.0.dev0) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.0.0->transformers==5.0.0.dev0) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.0.0->transformers==5.0.0.dev0) (0.28.1)\n",
      "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.0.0->transformers==5.0.0.dev0) (1.5.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.0.0->transformers==5.0.0.dev0) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==5.0.0.dev0) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==5.0.0.dev0) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==5.0.0.dev0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==5.0.0.dev0) (2025.11.12)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->transformers==5.0.0.dev0) (8.3.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.0.0->transformers==5.0.0.dev0) (4.12.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.0.0->transformers==5.0.0.dev0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.0.0->transformers==5.0.0.dev0) (0.16.0)\n",
      "Downloading huggingface_hub-1.1.6-py3-none-any.whl (516 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m516.1/516.1 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for transformers: filename=transformers-5.0.0.dev0-py3-none-any.whl size=10801169 sha256=ff869de7cfbc126c1d396596aaab2a30638ac9b37ebee79a409a207858978f16\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-qmt6sf4w/wheels/54/cb/3f/83103de5575c534436d6a4686686dead458238dfaf1147e98d\n",
      "Successfully built transformers\n",
      "Installing collected packages: huggingface-hub, transformers\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.36.0\n",
      "    Uninstalling huggingface-hub-0.36.0:\n",
      "      Successfully uninstalled huggingface-hub-0.36.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sentence-transformers 5.1.2 requires transformers<5.0.0,>=4.41.0, but you have transformers 5.0.0.dev0 which is incompatible.\n",
      "gradio 5.50.0 requires pillow<12.0,>=8.0, but you have pillow 12.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed huggingface-hub-1.1.6 transformers-5.0.0.dev0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "transformers"
        ]
       },
       "id": "8affa1950d6a4cf78ba4b7124a31f3a6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting git+https://github.com/huggingface/peft.git\n",
      "  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-l0fbvdvh\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-l0fbvdvh\n",
      "  Resolved https://github.com/huggingface/peft.git to commit b10527e82c2171568f538f5b822817e8a753672a\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from peft==0.18.1.dev0) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.18.1.dev0) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft==0.18.1.dev0) (7.1.3)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from peft==0.18.1.dev0) (6.0.3)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.18.1.dev0) (2.9.1)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from peft==0.18.1.dev0) (5.0.0.dev0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from peft==0.18.1.dev0) (4.67.1)\n",
      "Collecting accelerate>=0.21.0 (from peft==0.18.1.dev0)\n",
      "  Using cached accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from peft==0.18.1.dev0) (0.7.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.18.1.dev0) (1.1.6)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft==0.18.1.dev0) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft==0.18.1.dev0) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft==0.18.1.dev0) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft==0.18.1.dev0) (0.28.1)\n",
      "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft==0.18.1.dev0) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft==0.18.1.dev0) (0.20.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft==0.18.1.dev0) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (3.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (3.5.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->peft==0.18.1.dev0) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers->peft==0.18.1.dev0) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->peft==0.18.1.dev0) (0.22.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.25.0->peft==0.18.1.dev0) (4.12.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.25.0->peft==0.18.1.dev0) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.25.0->peft==0.18.1.dev0) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.25.0->peft==0.18.1.dev0) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub>=0.25.0->peft==0.18.1.dev0) (0.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft==0.18.1.dev0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft==0.18.1.dev0) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->peft==0.18.1.dev0) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->peft==0.18.1.dev0) (2.5.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface_hub>=0.25.0->peft==0.18.1.dev0) (8.3.1)\n",
      "Using cached accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
      "Building wheels for collected packages: peft\n",
      "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for peft: filename=peft-0.18.1.dev0-py3-none-any.whl size=566748 sha256=e6dcf63b4bcd6c4bdaa6e7fcd507c2e2c85d014ff39ddb47c0484024fd035e1b\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-3v4csasi/wheels/5d/16/61/117d50be36b7cb532817817523554825ff840d223c0f65c2c4\n",
      "Successfully built peft\n",
      "Installing collected packages: accelerate, peft\n",
      "Successfully installed accelerate-1.12.0 peft-0.18.1.dev0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "accelerate",
         "peft"
        ]
       },
       "id": "f79eacbe7fc349098685adf539ffad32"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting git+https://github.com/huggingface/accelerate.git\n",
      "  Cloning https://github.com/huggingface/accelerate.git to /tmp/pip-req-build-w9qx_kq4\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate.git /tmp/pip-req-build-w9qx_kq4\n",
      "  Resolved https://github.com/huggingface/accelerate.git to commit a72834ca8996f882208d4946d9180e626ae5c9c8\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate==1.13.0.dev0) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==1.13.0.dev0) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate==1.13.0.dev0) (7.1.3)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate==1.13.0.dev0) (6.0.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==1.13.0.dev0) (2.9.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==1.13.0.dev0) (1.1.6)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate==1.13.0.dev0) (0.7.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate==1.13.0.dev0) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate==1.13.0.dev0) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate==1.13.0.dev0) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate==1.13.0.dev0) (0.28.1)\n",
      "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate==1.13.0.dev0) (1.5.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate==1.13.0.dev0) (4.67.1)\n",
      "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate==1.13.0.dev0) (0.20.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate==1.13.0.dev0) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.13.0.dev0) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.13.0.dev0) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.13.0.dev0) (3.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.13.0.dev0) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.13.0.dev0) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.13.0.dev0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.13.0.dev0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.13.0.dev0) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.13.0.dev0) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.13.0.dev0) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.13.0.dev0) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.13.0.dev0) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.13.0.dev0) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.13.0.dev0) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.13.0.dev0) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.13.0.dev0) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.13.0.dev0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.13.0.dev0) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.13.0.dev0) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.13.0.dev0) (3.5.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate==1.13.0.dev0) (4.12.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate==1.13.0.dev0) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate==1.13.0.dev0) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate==1.13.0.dev0) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate==1.13.0.dev0) (0.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate==1.13.0.dev0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate==1.13.0.dev0) (3.0.3)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface_hub>=0.21.0->accelerate==1.13.0.dev0) (8.3.1)\n",
      "Building wheels for collected packages: accelerate\n",
      "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for accelerate: filename=accelerate-1.13.0.dev0-py3-none-any.whl size=381249 sha256=e9d170ea922a74174c8c6e924a8a3c20bc267741843c3a1753d99dffb4796e7b\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-2glzthoy/wheels/5a/20/fb/1221fe933b56fe7ac69fd00159d9a1950bc8ced38198abc18f\n",
      "Successfully built accelerate\n",
      "Installing collected packages: accelerate\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 1.12.0\n",
      "    Uninstalling accelerate-1.12.0:\n",
      "      Successfully uninstalled accelerate-1.12.0\n",
      "Successfully installed accelerate-1.13.0.dev0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "accelerate"
        ]
       },
       "id": "bdc1039edb3a4bd783e7a7fcd91c57e5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: qwen-vl-utils in /usr/local/lib/python3.12/dist-packages (0.0.14)\n",
      "Requirement already satisfied: av in /usr/local/lib/python3.12/dist-packages (from qwen-vl-utils) (16.0.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from qwen-vl-utils) (25.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from qwen-vl-utils) (12.0.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from qwen-vl-utils) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->qwen-vl-utils) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->qwen-vl-utils) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->qwen-vl-utils) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->qwen-vl-utils) (2025.11.12)\n",
      "‚úÖ Kurulum tamamlandƒ±! ≈ûimdi eƒüitim kodunu √ßalƒ±≈ütƒ±rabilirsin.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -U --force-reinstall bitsandbytes torch transformers peft datasets accelerate qwen-vl-utils -q"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3mfYQ-Z81L9x",
    "outputId": "708d38c3-4aed-4c84-d00f-e0ca0ff87bb3"
   },
   "id": "3mfYQ-Z81L9x",
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m75.1/75.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m891.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m556.4/556.4 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m380.9/380.9 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m201.0/201.0 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m150.3/150.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m807.9/807.9 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m803.5/803.5 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m507.2/507.2 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m40.5/40.5 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m263.3/263.3 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m193.9/193.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m159.4/159.4 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m153.5/153.5 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m71.0/71.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m129.8/129.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m113.4/113.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m256.1/256.1 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m221.6/221.6 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m377.3/377.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
      "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
      "torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\n",
      "torchvision 0.24.0+cu126 requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.5 which is incompatible.\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
      "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.5 which is incompatible.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
      "gradio 5.50.0 requires pillow<12.0,>=8.0, but you have pillow 12.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoModelForVision2Seq, AutoProcessor\n",
    "from peft import PeftModel\n",
    "\n",
    "# --- AYARLAR ---\n",
    "BASE_MODEL_ID = \"Qwen/Qwen2-VL-2B-Instruct\"\n",
    "ADAPTER_DIR = \"./qwen2-vl-turkish-food-text-only\"\n",
    "\n",
    "print(\"‚è≥ Ana model y√ºkleniyor...\")\n",
    "model = AutoModelForVision2Seq.from_pretrained(\n",
    "    BASE_MODEL_ID,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(BASE_MODEL_ID, trust_remote_code=True)\n",
    "\n",
    "print(f\"üìÇ Adapt√∂rler y√ºkleniyor...\")\n",
    "try:\n",
    "    model = PeftModel.from_pretrained(model, ADAPTER_DIR)\n",
    "    print(\"‚úÖ Hazƒ±r!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Hata: {e}\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# --- G√úNCELLENMƒ∞≈û SORU SORMA FONKSƒ∞YONU ---\n",
    "def modele_sor(soru):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": soru}]}\n",
    "    ]\n",
    "\n",
    "    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "    inputs = processor(\n",
    "        text=[text],\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(model.device)\n",
    "\n",
    "    # --- TEKRAR SORUNUNU √á√ñZEN AYARLAR BURADA ---\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=256,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            repetition_penalty=1.2, # <-- YENƒ∞: Tekrarƒ± cezalandƒ±rƒ±r (1.0 ile 1.5 arasƒ±)\n",
    "            no_repeat_ngram_size=3, # <-- YENƒ∞: 3 kelimelik √∂beklerin aynƒ±sƒ±nƒ± tekrarlamaz\n",
    "            eos_token_id=processor.tokenizer.eos_token_id, # C√ºmle biti≈üini garantiye al\n",
    "            pad_token_id=processor.tokenizer.pad_token_id\n",
    "        )\n",
    "\n",
    "    generated_ids_trimmed = [\n",
    "        out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "\n",
    "    output_text = processor.batch_decode(\n",
    "        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    )\n",
    "\n",
    "    return output_text[0]\n",
    "\n",
    "# --- HATA Y√ñNETƒ∞Mƒ∞ OLAN D√ñNG√ú ---\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"ü§ñ T√úRK MUTFAƒûI ASƒ∞STANI (D√ºzeltilmi≈ü Versiyon)\")\n",
    "print(\"√áƒ±kmak i√ßin 'Stop' butonuna basabilirsin.\")\n",
    "print(\"=\"*40 + \"\\n\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        soru = input(\"SORU SOR (√áƒ±kƒ±≈ü i√ßin q): \")\n",
    "        if soru.lower() in [\"q\", \"exit\", \"√ßƒ±k\"]:\n",
    "            print(\"G√ºle g√ºle! üëã\")\n",
    "            break\n",
    "\n",
    "        if soru.strip() == \"\":\n",
    "            continue\n",
    "\n",
    "        print(\"ü§î D√º≈ü√ºn√ºyor...\")\n",
    "        cevap = modele_sor(soru)\n",
    "        print(f\"\\nCEVAP:\\n{cevap}\\n\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    # Stop butonuna basƒ±nca burasƒ± √ßalƒ±≈üƒ±r\n",
    "    print(\"\\n\\n‚õî ƒ∞≈ülem kullanƒ±cƒ± tarafƒ±ndan durduruldu. G√ºle g√ºle! üëã\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 991,
     "referenced_widgets": [
      "f938f573ac0740b4b51017356e9426a8",
      "fbb8e56aa2a94758a0c389414344748d",
      "37d65c36d12c4d3f93e928629da1cb13",
      "dc9789c128a842488c7b0e12658f0c3a",
      "cbdad8d453c34de7bd2ad2a6a80c8a3f",
      "4330c1660b2a464bb62b8fc166f77857",
      "fba4d90d8a3443fc9b49f7e7d81dae46",
      "0b697ad4000a4848b280cac8383071a7",
      "ab77b6c166b1439cb247db2fc26c9fbe",
      "6cac3a6b539e49548058a5c0b653ad3a",
      "1778b9cbd8b74a82b10b412fc2b4fdc5"
     ]
    },
    "id": "szRfMY53ULIu",
    "outputId": "543c98de-c40c-409f-b3a2-0c50fccb0377"
   },
   "id": "szRfMY53ULIu",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "‚è≥ Ana model y√ºkleniyor...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f938f573ac0740b4b51017356e9426a8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "üìÇ Adapt√∂rler y√ºkleniyor...\n",
      "‚ùå Hata: Can't find 'adapter_config.json' at './qwen2-vl-turkish-food-text-only'\n",
      "\n",
      "========================================\n",
      "ü§ñ T√úRK MUTFAƒûI ASƒ∞STANI (D√ºzeltilmi≈ü Versiyon)\n",
      "√áƒ±kmak i√ßin 'Stop' butonuna basabilirsin.\n",
      "========================================\n",
      "\n",
      "SORU SOR (√áƒ±kƒ±≈ü i√ßin q): Geleneksel '≈ûalgam Suyu' √ºretiminde kullanƒ±lan 'Setik' nedir? \n",
      "ü§î D√º≈ü√ºn√ºyor...\n",
      "\n",
      "CEVAP:\n",
      "\"Setik\", genellikle \"≈üalgam suyu\" veya \"sulama suyu\"s√ºrg√ºnlerinin bir par√ßasƒ±dƒ±r ve bu, suyunun sularƒ±nƒ± belirli bir ≈üekilde d√ºzenlemesine yardƒ±mcƒ± olur. Bu y√ºzden, ≈üalgam s√ºy√ºn√ºn √ºretimi sƒ±rasƒ±nda kullanƒ±lƒ±r.\n",
      "\n",
      "Bu nedenle, Setik, ≈üalga suyu'nun kirlenmesini √∂nleyerek, suya daha iyi √ß√∂z√ºn√ºrl√ºk saƒülar. Ayrƒ±ca, setik, suyu daha hƒ±zlƒ± ve daha net bir ≈üekilde sƒ±vƒ±da tutar.\n",
      "\n",
      "------------------------------\n",
      "SORU SOR (√áƒ±kƒ±≈ü i√ßin q): Geleneksel T√ºrk mutfaƒüƒ±nda israfƒ± √∂nlemeye y√∂nelik 'Tirit' gibi yemeklerin mantƒ±ƒüƒ± nedir?\"\n",
      "ü§î D√º≈ü√ºn√ºyor...\n",
      "\n",
      "CEVAP:\n",
      "\"Tirit\" genellikle T√ºrkiye'deki gelenekel bir yemeƒüi ve i√ßecekleri i√ßin kullanƒ±lan terimdir. Bu terimin anlamƒ±, bu t√ºr yemekteki \"tirit\", ya da diƒüer bazƒ± √∂ƒüeleriyle ilgili bir √∂nemi vardƒ±r. Ancak belirttiƒüiniz gibi, her yerde farklƒ±lƒ±k g√∂steren bir√ßok fakt√∂r de etkileyecektir: geografya, sosyal ortam, k√ºlt√ºrel etkinlikleri, eƒüitim d√ºzeyleri vb.\n",
      "\n",
      "Bunlar nedeniyle, \"Tirit\" adlƒ± yemeyi veya i√ße√ßini nasƒ±l tanƒ±mlayabiliriz? ƒ∞≈üte birka√ß √∂rnek:\n",
      "\n",
      "1) Tƒ±rnak: Tƒ±rnaka, √∂zellikle doƒüu ve batƒ± b√∂lgesinde yaygƒ±n olan bir yemektir. Yumurta, kuru balƒ±k, zeytinyaƒüƒ± ve √ße≈üitli meyveler i√ßerir.\n",
      "2) Kebap: T√ºrkiye'nin en pop√ºler yemegidir. Sƒ±cak, su doludan yapƒ±lan kebaplar, √∂zellikle ƒ∞stanbul'un popular olduƒüu b√∂lgelerinde √ßok sergilendirilir.\n",
      "3) Piyaz: T√ºrkiye'de olduk√ßa yaygƒ±ndƒ±r\n",
      "\n",
      "------------------------------\n",
      "SORU SOR (√áƒ±kƒ±≈ü i√ßin q): su nedir?\n",
      "ü§î D√º≈ü√ºn√ºyor...\n",
      "\n",
      "CEVAP:\n",
      "Su, birer n√∂trik kimyasal elementi ve atmosferdeki en yaygƒ±n olan gazƒ±dƒ±r. Su, suyunun i√ßine girmesiyle olu≈üur ve bu y√ºzden \"suyu\" denilen bir ≈üeydir. Su'n√ºn √∂zellikleri arasƒ±nda, sƒ±caklƒ±kla ilgili olarak √ßok fazlasƒ± vardƒ±r: y√ºksek sƒ±caklƒ±klarƒ±nda (√∂rneƒüin, g√ºne≈üten), d√º≈ü√ºk sƒ±caklƒ±klarda (√∂rnegin, kƒ±≈üta) ve genellikle normal sƒ±caklara ula≈üan suya g√∂re deƒüi≈ümektedir.\n",
      "\n",
      "S√ºre√ßlerde kullanƒ±lan su, suyu kullanma gereksinimleri ile uyumlu olmalƒ±dƒ±r. Bu nedenle, bazƒ± durumlarda suyun kullanƒ±lmasƒ± zor hale gelmezken, diƒüer durumlardaki zaman i√ßinde daha az veya daha fazla su t√ºketimi gerektiƒüi i√ßin ba≈üka bir y√∂ntem se√ßilmesi gereklidir.\n",
      "\n",
      "------------------------------\n",
      "SORU SOR (√áƒ±kƒ±≈ü i√ßin q): Geleneksel '≈ûalgam Suyu' √ºretiminde kullanƒ±lan 'Setik' nedir? \n",
      "ü§î D√º≈ü√ºn√ºyor...\n",
      "\n",
      "CEVAP:\n",
      "\"Setik\", genellikle \"≈üalgam suyu\" veya \"sulama suyu\"s√ºrg√ºnlerinin bir par√ßasƒ±dƒ±r ve bu, suyunun sularƒ±nƒ±n kirlenmesini √∂nleyerek daha iyi kalmasƒ±nƒ± saƒülar.\n",
      "\n",
      "Bu y√ºzden Setik, ≈üalgam sularƒ±nƒ± temizlemeye yardƒ±mcƒ± olur ve aynƒ± zamanda suyunuzun kalitesine katkƒ±da bulunur. Bu nedenle, √∂zellikle de yaƒümur gibi hava durumlarƒ±nda kullanƒ±lƒ±rken √∂nemlidir.\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "‚õî ƒ∞≈ülem kullanƒ±cƒ± tarafƒ±ndan durduruldu. G√ºle g√ºle! üëã\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoModelForVision2Seq, AutoProcessor\n",
    "from peft import PeftModel\n",
    "\n",
    "# --- AYARLAR ---\n",
    "BASE_MODEL_ID = \"Qwen/Qwen2-VL-2B-Instruct\"\n",
    "ADAPTER_DIR = \"./qwen2-vl-turkish-food-v2\" #eƒüitim √ßƒ±ktƒ±sƒ±\n",
    "\n",
    "print(\" Ana model y√ºkleniyor...\")\n",
    "# 1. Ana Modeli Y√ºkle\n",
    "base_model = AutoModelForVision2Seq.from_pretrained(\n",
    "    BASE_MODEL_ID,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# 2. Processor Y√ºkle\n",
    "processor = AutoProcessor.from_pretrained(BASE_MODEL_ID, trust_remote_code=True)\n",
    "\n",
    "# 3. Senin Eƒüittiƒüin Adapt√∂r√º Y√ºkle\n",
    "print(f\" Veriler ({ADAPTER_DIR}) modele ekleniyor...\")\n",
    "try:\n",
    "    model = PeftModel.from_pretrained(base_model, ADAPTER_DIR)\n",
    "    print(\" Adapt√∂r ba≈üarƒ±yla y√ºklendi! Teste hazƒ±rƒ±z.\")\n",
    "except Exception as e:\n",
    "    print(f\" HATA: Adapt√∂r bulunamadƒ±. Klas√∂r ismini kontrol et. Hata: {e}\")\n",
    "    # Hata olursa base modelle devam etsin\n",
    "    model = base_model\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# --- SORU CEVAP FONKSƒ∞YONU ---\n",
    "def sor_bakalim(soru):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": soru}]}\n",
    "    ]\n",
    "\n",
    "    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "    inputs = processor(\n",
    "        text=[text],\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(model.device)\n",
    "\n",
    "    # Parametreleri, modelin tekrara d√º≈ümemesi i√ßin ayarladƒ±k\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=200,    # Cevap uzunluƒüu\n",
    "            do_sample=True,        # Yaratƒ±cƒ±lƒ±k a√ßƒ±k\n",
    "            temperature=0.6,       # 0.6 biraz daha tutarlƒ± yapar (0.1 robot, 1.0 ≈üair)\n",
    "            top_p=0.9,\n",
    "            repetition_penalty=1.2, # Tekrarƒ± √∂nler\n",
    "            no_repeat_ngram_size=3  # \"Ali topu attƒ±, Ali topu attƒ±\" gibi tekrarlarƒ± engeller\n",
    "        )\n",
    "\n",
    "    generated_ids_trimmed = [\n",
    "        out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "\n",
    "    output_text = processor.batch_decode(\n",
    "        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    )\n",
    "\n",
    "    return output_text[0]\n",
    "\n",
    "# --- CANLI TEST PANELƒ∞ ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\" TEST A≈ûAMASI BA≈ûLADI\")\n",
    "print(\"√áƒ±kmak i√ßin 'q' yazabilirsin.\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        soru = input(\"\\nSen: \")\n",
    "        if soru.lower() in [\"q\", \"exit\", \"√ßƒ±k\", \"dur\"]:\n",
    "            print(\"Test bitti. Sonu√ßlar tatmin ediciyse merge i≈ülemine ge√ßebilirsin. üëã\")\n",
    "            break\n",
    "\n",
    "        if len(soru) < 2: continue\n",
    "\n",
    "        print(\" Model Cevabƒ±:\")\n",
    "        cevap = sor_bakalim(soru)\n",
    "        print(f\"üëâ {cevap}\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n Test kullanƒ±cƒ± tarafƒ±ndan durduruldu.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641,
     "referenced_widgets": [
      "1a52679035fd4d4ab8813b8c935f8950",
      "15e2622ad90a4e16a4add2a2f023ea34",
      "7aafcc43d33a4e04b16eeedcd7e31548",
      "73febf13640d4afd8bbd0956879e5e24",
      "af24e77c87a3466d9d2d2edd22781afa",
      "24e7ff78057f4460b9e95b30f853fb9c",
      "3a063be6b8aa45e2a9f90831ddbd8f39",
      "32a6ee0c66af40778fc3f21d607b752c",
      "98ff8615a6b2494fac8e293bc0627d86",
      "abff06cb124849b4a13513541592ebed",
      "1afdd1d174b948f08fade1a6825f7f9b"
     ]
    },
    "id": "4gSg7h05t_gV",
    "outputId": "9b7ed40b-6606-4ead-c25f-df9bd4c9dc44"
   },
   "id": "4gSg7h05t_gV",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Unrecognized keys in `rope_parameters` for 'rope_type'='default': {'mrope_section'}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " Ana model y√ºkleniyor...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading weights:   0%|          | 0/729 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1a52679035fd4d4ab8813b8c935f8950"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " Veriler (./qwen2-vl-turkish-food-v2) modele ekleniyor...\n",
      " Adapt√∂r ba≈üarƒ±yla y√ºklendi! Teste hazƒ±rƒ±z.\n",
      "\n",
      "==================================================\n",
      " TEST A≈ûAMASI BA≈ûLADI\n",
      "√áƒ±kmak i√ßin 'q' yazabilirsin.\n",
      "==================================================\n",
      "\n",
      "\n",
      "Sen: Geleneksel '≈ûalgam Suyu' √ºretiminde kullanƒ±lan 'Setik' nedir?\n",
      " Model Cevabƒ±:\n",
      "üëâ ≈ûalg√°m suyu √ºretiminde ham madde olarak kullanƒ±lan bulgur ununa 'setik' adƒ± verilir. Bu un, ek≈üi hamur mayasƒ± ile karƒ±≈ütƒ±rƒ±larak ilk fermantasyon a≈üamasƒ±nƒ± ba≈ülatƒ±r.\n",
      "------------------------------\n",
      "\n",
      "Sen: Pekmezde HMF (Hidroksimetil Furfural) olu≈üumu neden risklidir?\n",
      " Model Cevabƒ±:\n",
      "üëâ Peki≈ü mutfak k√ºlt√ºr√ºnde uzun s√ºre kaynatƒ±larak t√ºketilmemesi (pekmez tarhanasƒ±), hmf bile≈üikleri i√ßerdiƒüi i√ßin kan ≈üekerini hƒ±zlƒ± y√ºkseltebilir ve diabet hastalarƒ±nƒ±n beslenmesinde gerekli ki·ªÉmollere maruz bƒ±rakƒ±lƒ±r.\n",
      "------------------------------\n",
      "\n",
      "Sen: Mara≈ü Tarhanasƒ±'nƒ±n diƒüer tarhanalardan farkƒ± nedir?\n",
      " Model Cevabƒ±:\n",
      "üëâ MARA≈û TARHANASI, YEREL Geleneksel tarhana yapƒ±mƒ±nda kullanƒ±lan unun kendi akƒ± ile kurutulmu≈ü ve kapaƒüƒ± kapalƒ± olarak √ºretilmesi nedeniyle darƒ± ve kalsiyum i√ßeriƒüi azaltƒ±lmƒ±≈ü bir tarhana t√ºr√ºd√ºr.\n",
      "------------------------------\n",
      "\n",
      "Sen: Pekmez yapƒ±mƒ±nda kullanƒ±lan topraƒüƒ±n i≈ülevi nedir?\n",
      " Model Cevabƒ±:\n",
      "üëâ Geleneksel pekmez yapƒ±mƒ±arda, used to adƒ± verilen ve ek≈üiliƒüi azaltan bir toprak, fermantasyonu durdurarak asetik asit bakterilerinin geli≈üimi i√ßin gerekli ko≈üullar saƒülar.\n",
      "------------------------------\n",
      "\n",
      " Test kullanƒ±cƒ± tarafƒ±ndan durduruldu.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"üßπ √áakƒ±≈üan k√ºt√ºphaneler siliniyor...\")\n",
    "!pip uninstall -y transformers accelerate peft bitsandbytes\n",
    "\n",
    "print(\"‚ú® Uyumlu versiyonlar sƒ±fƒ±rdan kuruluyor...\")\n",
    "!pip install -U transformers accelerate peft bitsandbytes datasets torch qwen-vl-utils\n",
    "\n",
    "print(\"‚úÖ Kurulum bitti! L√ºtfen a≈üaƒüƒ±yƒ± oku üëá\")"
   ],
   "metadata": {
    "id": "YKnTZCWsKngg",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b3c6e801-4733-42ae-8dc9-915571fb5aaa"
   },
   "id": "YKnTZCWsKngg",
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "üßπ √áakƒ±≈üan k√ºt√ºphaneler siliniyor...\n",
      "Found existing installation: transformers 4.57.3\n",
      "Uninstalling transformers-4.57.3:\n",
      "  Successfully uninstalled transformers-4.57.3\n",
      "Found existing installation: accelerate 1.12.0\n",
      "Uninstalling accelerate-1.12.0:\n",
      "  Successfully uninstalled accelerate-1.12.0\n",
      "Found existing installation: peft 0.18.0\n",
      "Uninstalling peft-0.18.0:\n",
      "  Successfully uninstalled peft-0.18.0\n",
      "Found existing installation: bitsandbytes 0.48.2\n",
      "Uninstalling bitsandbytes-0.48.2:\n",
      "  Successfully uninstalled bitsandbytes-0.48.2\n",
      "‚ú® Uyumlu versiyonlar sƒ±fƒ±rdan kuruluyor...\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting peft\n",
      "  Using cached peft-0.18.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting bitsandbytes\n",
      "  Using cached bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.4.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.1)\n",
      "Requirement already satisfied: qwen-vl-utils in /usr/local/lib/python3.12/dist-packages (0.0.14)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (7.1.3)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.1)\n",
      "Requirement already satisfied: av in /usr/local/lib/python3.12/dist-packages (from qwen-vl-utils) (16.0.1)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from qwen-vl-utils) (12.0.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.12.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Using cached transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "Using cached accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
      "Using cached peft-0.18.0-py3-none-any.whl (556 kB)\n",
      "Using cached bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl (59.4 MB)\n",
      "Installing collected packages: transformers, bitsandbytes, accelerate, peft\n",
      "Successfully installed accelerate-1.12.0 bitsandbytes-0.48.2 peft-0.18.0 transformers-4.57.3\n",
      "‚úÖ Kurulum bitti! L√ºtfen a≈üaƒüƒ±yƒ± oku üëá\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}